{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In \\[1\\]:\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    # from xgboost import XGBClassifier\n",
    "    from imblearn.over_sampling import SMOTE, SVMSMOTE\n",
    "    from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.preprocessing import StandardScaler, MinMaxScaler,OneHotEncoder\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.decomposition import PCA\n",
    "    from imblearn.pipeline import Pipeline as imbpipeline \n",
    "    from sklearn.feature_selection import SelectFromModel\n",
    "    from sklearn import svm\n",
    "\n",
    "1.  Exploratory Data Analysis\n",
    "\n",
    "In \\[2\\]:\n",
    "\n",
    "    df = pd.read_csv('predictive_maintainece_dataset.csv')\n",
    "\n",
    "In \\[3\\]:\n",
    "\n",
    "    df.shape\n",
    "\n",
    "Out\\[3\\]:\n",
    "\n",
    "    (124494, 12)\n",
    "\n",
    "In \\[4\\]:\n",
    "\n",
    "    def check_null(df):\n",
    "        return df.isna().sum() * 100/len(df)\n",
    "    check_null(df)\n",
    "\n",
    "Out\\[4\\]:\n",
    "\n",
    "    date       0.0\n",
    "    device     0.0\n",
    "    failure    0.0\n",
    "    metric1    0.0\n",
    "    metric2    0.0\n",
    "    metric3    0.0\n",
    "    metric4    0.0\n",
    "    metric5    0.0\n",
    "    metric6    0.0\n",
    "    metric7    0.0\n",
    "    metric8    0.0\n",
    "    metric9    0.0\n",
    "    dtype: float64\n",
    "\n",
    "In \\[5\\]:\n",
    "\n",
    "    df.info()\n",
    "\n",
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "    RangeIndex: 124494 entries, 0 to 124493\n",
    "    Data columns (total 12 columns):\n",
    "     #   Column   Non-Null Count   Dtype \n",
    "    ---  ------   --------------   ----- \n",
    "     0   date     124494 non-null  object\n",
    "     1   device   124494 non-null  object\n",
    "     2   failure  124494 non-null  int64 \n",
    "     3   metric1  124494 non-null  int64 \n",
    "     4   metric2  124494 non-null  int64 \n",
    "     5   metric3  124494 non-null  int64 \n",
    "     6   metric4  124494 non-null  int64 \n",
    "     7   metric5  124494 non-null  int64 \n",
    "     8   metric6  124494 non-null  int64 \n",
    "     9   metric7  124494 non-null  int64 \n",
    "     10  metric8  124494 non-null  int64 \n",
    "     11  metric9  124494 non-null  int64 \n",
    "    dtypes: int64(10), object(2)\n",
    "    memory usage: 11.4+ MB\n",
    "\n",
    "In \\[6\\]:\n",
    "\n",
    "    # f = pd.df(np.random.rand(30,6),colums = ['metric1','metri2','metric3','metric4','metric5','metric6','metric7','metric8','metric9','failure'])\n",
    "\n",
    "In \\[7\\]:\n",
    "\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    sns.heatmap(df.corr())\n",
    "\n",
    "Out\\[7\\]:\n",
    "\n",
    "    <AxesSubplot:>\n",
    "\n",
    "![](attachment:vertopal_ff7a4e3872b24f67b72ab8786db2a741/f2b0f5d92544571f294dccf4d9b0140c950f9862.png)\n",
    "\n",
    "Dropping One of the columns of metric7, metric8 since they both are\n",
    "having High Correlation\n",
    "\n",
    "In \\[8\\]:\n",
    "\n",
    "    df.drop(['metric8'],axis=1,inplace=True)\n",
    "\n",
    "In \\[9\\]:\n",
    "\n",
    "    duplicate = df[df.duplicated(keep=False)]\n",
    "    duplicate\n",
    "    df = df.drop_duplicates(keep='last')\n",
    "    df.shape\n",
    "\n",
    "Out\\[9\\]:\n",
    "\n",
    "    (124493, 11)\n",
    "\n",
    "Observing the distributions of Target class\n",
    "\n",
    "In \\[10\\]:\n",
    "\n",
    "    print(df['failure'].value_counts())\n",
    "    import matplotlib.pyplot as plt\n",
    "    count_classes = pd.value_counts(df['failure'], sort=True)\n",
    "    count_classes.plot(kind = 'bar', rot=7)\n",
    "    plt.title(\"Target Class Distribution\")\n",
    "    plt.xlabel(\"failure\")\n",
    "    plt.ylabel(\"count\")\n",
    "\n",
    "    0    124387\n",
    "    1       106\n",
    "    Name: failure, dtype: int64\n",
    "\n",
    "Out\\[10\\]:\n",
    "\n",
    "    Text(0, 0.5, 'count')\n",
    "\n",
    "![](attachment:vertopal_ff7a4e3872b24f67b72ab8786db2a741/67213e103aac42415d73b8fa5585cc21980d37e7.png)\n",
    "\n",
    "Observing the trend of daily entries\n",
    "\n",
    "In \\[11\\]:\n",
    "\n",
    "    daily_records = df['date'].value_counts()\n",
    "    daily_records.plot()\n",
    "\n",
    "Out\\[11\\]:\n",
    "\n",
    "    <AxesSubplot:>\n",
    "\n",
    "![](attachment:vertopal_ff7a4e3872b24f67b72ab8786db2a741/0b0f79b6909e4cd01d260d98dbd2468a8b451f52.png)\n",
    "\n",
    "Extracting month column from the given date\n",
    "\n",
    "In \\[12\\]:\n",
    "\n",
    "    df['date'] = df['date'].astype('datetime64[ns]')\n",
    "    df['month'] = pd.DatetimeIndex(df['date']).month\n",
    "    # df['day_of_week'] = df['date'].dt.day_name()\n",
    "    # df['dayofyear'] = df['date'].dt.dayofyear\n",
    "    df.head()\n",
    "\n",
    "Out\\[12\\]:\n",
    "\n",
    "|     | date       | device   | failure | metric1   | metric2 | metric3 | metric4 | metric5 | metric6 | metric7 | metric9 | month |\n",
    "|-----|------------|----------|---------|-----------|---------|---------|---------|---------|---------|---------|---------|-------|\n",
    "| 0   | 2015-01-01 | S1F01085 | 0       | 215630672 | 55      | 0       | 52      | 6       | 407438  | 0       | 7       | 1     |\n",
    "| 1   | 2015-01-01 | S1F0166B | 0       | 61370680  | 0       | 3       | 0       | 6       | 403174  | 0       | 0       | 1     |\n",
    "| 2   | 2015-01-01 | S1F01E6Y | 0       | 173295968 | 0       | 0       | 0       | 12      | 237394  | 0       | 0       | 1     |\n",
    "| 3   | 2015-01-01 | S1F01JE0 | 0       | 79694024  | 0       | 0       | 0       | 6       | 410186  | 0       | 0       | 1     |\n",
    "| 4   | 2015-01-01 | S1F01R2B | 0       | 135970480 | 0       | 0       | 0       | 15      | 313173  | 0       | 3       | 1     |\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "     \n",
    "\n",
    "Observing trend of Monthly records\n",
    "\n",
    "In \\[13\\]:\n",
    "\n",
    "    daily_records = df['month'].value_counts()\n",
    "    daily_records.plot(kind = 'bar')\n",
    "\n",
    "Out\\[13\\]:\n",
    "\n",
    "    <AxesSubplot:>\n",
    "\n",
    "![](attachment:vertopal_ff7a4e3872b24f67b72ab8786db2a741/9c29c00a83aa59b201724f6aac2ec1ef68ebac99.png)\n",
    "\n",
    "In \\[14\\]:\n",
    "\n",
    "    import pandasql\n",
    "    sub_data = pandasql.sqldf(\"SELECT device,count(*) as num_of_days_alive FROM df group by device order by num_of_days_alive desc;\", globals())\n",
    "    # print(sub_data)\n",
    "\n",
    "In \\[15\\]:\n",
    "\n",
    "    failure_data=pandasql.sqldf(\"SELECT * FROM df where failure=1;\", globals())\n",
    "    failure_data\n",
    "\n",
    "Out\\[15\\]:\n",
    "\n",
    "|     | date                       | device   | failure | metric1   | metric2 | metric3 | metric4 | metric5 | metric6 | metric7 | metric9 | month |\n",
    "|-----|----------------------------|----------|---------|-----------|---------|---------|---------|---------|---------|---------|---------|-------|\n",
    "| 0   | 2015-01-05 00:00:00.000000 | S1F0RRB1 | 1       | 48467332  | 64776   | 0       | 841     | 8       | 39267   | 56      | 1       | 1     |\n",
    "| 1   | 2015-01-07 00:00:00.000000 | S1F0CTDN | 1       | 184069720 | 528     | 0       | 4       | 9       | 387871  | 32      | 3       | 1     |\n",
    "| 2   | 2015-01-09 00:00:00.000000 | W1F0PNA5 | 1       | 136429411 | 64784   | 0       | 406     | 30      | 224801  | 8       | 0       | 1     |\n",
    "| 3   | 2015-01-13 00:00:00.000000 | W1F13SRV | 1       | 188251248 | 2040    | 0       | 0       | 6       | 39345   | 32      | 1       | 1     |\n",
    "| 4   | 2015-01-14 00:00:00.000000 | W1F1230J | 1       | 220461296 | 0       | 0       | 0       | 14      | 325125  | 0       | 0       | 1     |\n",
    "| ... | ...                        | ...      | ...     | ...       | ...     | ...     | ...     | ...     | ...     | ...     | ...     | ...   |\n",
    "| 101 | 2015-08-04 00:00:00.000000 | W1F1CB5E | 1       | 16043296  | 88      | 0       | 0       | 9       | 30      | 0       | 0       | 8     |\n",
    "| 102 | 2015-08-18 00:00:00.000000 | Z1F0MRPJ | 1       | 65654088  | 0       | 0       | 0       | 9       | 298592  | 0       | 11      | 8     |\n",
    "| 103 | 2015-10-05 00:00:00.000000 | S1F0JGJV | 1       | 13739704  | 0       | 0       | 18      | 8       | 343760  | 0       | 0       | 10    |\n",
    "| 104 | 2015-10-09 00:00:00.000000 | Z1F14BGY | 1       | 85259320  | 0       | 0       | 164     | 8       | 262932  | 0       | 0       | 10    |\n",
    "| 105 | 2015-10-26 00:00:00.000000 | W1F0T0B1 | 1       | 95073232  | 0       | 0       | 7       | 9       | 354861  | 22      | 0       | 10    |\n",
    "\n",
    "106 rows × 12 columns\n",
    "\n",
    "Observing the monthly failures\n",
    "\n",
    "In \\[16\\]:\n",
    "\n",
    "    viz=pandasql.sqldf(\"SELECT count(*) as num_of_failed,month FROM failure_data group by month order by num_of_failed desc ;\", globals())\n",
    "    print(viz)\n",
    "\n",
    "       num_of_failed  month\n",
    "    0             24      1\n",
    "    1             21      5\n",
    "    2             16      7\n",
    "    3             14      2\n",
    "    4              9      4\n",
    "    5              9      3\n",
    "    6              6      6\n",
    "    7              4      8\n",
    "    8              3     10\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "     \n",
    "\n",
    "In \\[17\\]:\n",
    "\n",
    "    # viz=pandasql.sqldf(\"SELECT count(*) as num_of_failed,month FROM failure_data group by month order by num_of_failed desc ;\", globals())\n",
    "\n",
    "In \\[18\\]:\n",
    "\n",
    "    # df1=df.query(\"`failure` == 1\")\n",
    "    # #grouped=df1.groupby(['date','device'])\n",
    "    # df1.head(106)\n",
    "\n",
    "In \\[19\\]:\n",
    "\n",
    "    df['device'].nunique()\n",
    "\n",
    "Out\\[19\\]:\n",
    "\n",
    "    1169\n",
    "\n",
    "In \\[20\\]:\n",
    "\n",
    "    y  = df['failure']\n",
    "    y.value_counts()\n",
    "\n",
    "Out\\[20\\]:\n",
    "\n",
    "    0    124387\n",
    "    1       106\n",
    "    Name: failure, dtype: int64\n",
    "\n",
    "In \\[21\\]:\n",
    "\n",
    "    df\n",
    "\n",
    "Out\\[21\\]:\n",
    "\n",
    "|        | date       | device   | failure | metric1   | metric2 | metric3 | metric4 | metric5 | metric6 | metric7 | metric9 | month |\n",
    "|--------|------------|----------|---------|-----------|---------|---------|---------|---------|---------|---------|---------|-------|\n",
    "| 0      | 2015-01-01 | S1F01085 | 0       | 215630672 | 55      | 0       | 52      | 6       | 407438  | 0       | 7       | 1     |\n",
    "| 1      | 2015-01-01 | S1F0166B | 0       | 61370680  | 0       | 3       | 0       | 6       | 403174  | 0       | 0       | 1     |\n",
    "| 2      | 2015-01-01 | S1F01E6Y | 0       | 173295968 | 0       | 0       | 0       | 12      | 237394  | 0       | 0       | 1     |\n",
    "| 3      | 2015-01-01 | S1F01JE0 | 0       | 79694024  | 0       | 0       | 0       | 6       | 410186  | 0       | 0       | 1     |\n",
    "| 4      | 2015-01-01 | S1F01R2B | 0       | 135970480 | 0       | 0       | 0       | 15      | 313173  | 0       | 3       | 1     |\n",
    "| ...    | ...        | ...      | ...     | ...       | ...     | ...     | ...     | ...     | ...     | ...     | ...     | ...   |\n",
    "| 124489 | 2015-11-02 | Z1F0MA1S | 0       | 18310224  | 0       | 0       | 0       | 10      | 353705  | 8       | 0       | 11    |\n",
    "| 124490 | 2015-11-02 | Z1F0Q8RT | 0       | 172556680 | 96      | 107     | 4       | 11      | 332792  | 0       | 13      | 11    |\n",
    "| 124491 | 2015-11-02 | Z1F0QK05 | 0       | 19029120  | 4832    | 0       | 0       | 11      | 350410  | 0       | 0       | 11    |\n",
    "| 124492 | 2015-11-02 | Z1F0QL3N | 0       | 226953408 | 0       | 0       | 0       | 12      | 358980  | 0       | 0       | 11    |\n",
    "| 124493 | 2015-11-02 | Z1F0QLC1 | 0       | 17572840  | 0       | 0       | 0       | 10      | 351431  | 0       | 70000   | 11    |\n",
    "\n",
    "124493 rows × 12 columns\n",
    "\n",
    "In \\[22\\]:\n",
    "\n",
    "    # pd.date_range(start = '2015-01-01', end = '2015-01-01' ).difference(df.index)\n",
    "\n",
    "In \\[23\\]:\n",
    "\n",
    "    df.drop(['failure','device','date'],axis=1,inplace=True)\n",
    "\n",
    "In \\[24\\]:\n",
    "\n",
    "    X = df \n",
    "\n",
    "In \\[25\\]:\n",
    "\n",
    "    df.head(10)\n",
    "\n",
    "Out\\[25\\]:\n",
    "\n",
    "|     | metric1   | metric2 | metric3 | metric4 | metric5 | metric6 | metric7 | metric9 | month |\n",
    "|-----|-----------|---------|---------|---------|---------|---------|---------|---------|-------|\n",
    "| 0   | 215630672 | 55      | 0       | 52      | 6       | 407438  | 0       | 7       | 1     |\n",
    "| 1   | 61370680  | 0       | 3       | 0       | 6       | 403174  | 0       | 0       | 1     |\n",
    "| 2   | 173295968 | 0       | 0       | 0       | 12      | 237394  | 0       | 0       | 1     |\n",
    "| 3   | 79694024  | 0       | 0       | 0       | 6       | 410186  | 0       | 0       | 1     |\n",
    "| 4   | 135970480 | 0       | 0       | 0       | 15      | 313173  | 0       | 3       | 1     |\n",
    "| 5   | 68837488  | 0       | 0       | 41      | 6       | 413535  | 0       | 1       | 1     |\n",
    "| 6   | 227721632 | 0       | 0       | 0       | 8       | 402525  | 0       | 0       | 1     |\n",
    "| 7   | 141503600 | 0       | 0       | 1       | 19      | 494462  | 16      | 3       | 1     |\n",
    "| 8   | 8217840   | 0       | 1       | 0       | 14      | 311869  | 0       | 0       | 1     |\n",
    "| 9   | 116440096 | 0       | 378     | 9       | 9       | 407905  | 0       | 170     | 1     |\n",
    "\n",
    "Startified Split Splitting the data\n",
    "\n",
    "In \\[26\\]:\n",
    "\n",
    "    from sklearn.model_selection import train_test_split,GridSearchCV, StratifiedKFold\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=0.2,\n",
    "                                                        stratify=y,\n",
    "                                                        random_state=11)\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "     \n",
    "\n",
    "In \\[27\\]:\n",
    "\n",
    "    X_train['month'] = X_train['month'].astype(\"category\")\n",
    "    X_test['month'] = X_test['month'].astype(\"category\")\n",
    "\n",
    "    <ipython-input-27-536bbd704b12>:1: SettingWithCopyWarning: \n",
    "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
    "    Try using .loc[row_indexer,col_indexer] = value instead\n",
    "\n",
    "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "      X_train['month'] = X_train['month'].astype(\"category\")\n",
    "    <ipython-input-27-536bbd704b12>:2: SettingWithCopyWarning: \n",
    "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
    "    Try using .loc[row_indexer,col_indexer] = value instead\n",
    "\n",
    "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "      X_test['month'] = X_test['month'].astype(\"category\")\n",
    "\n",
    "Collecting all the numeraical and categorical features\n",
    "\n",
    "In \\[28\\]:\n",
    "\n",
    "    num_cols = X_train.select_dtypes(include=[\"number\"]).columns.to_list()\n",
    "    cat_cols = X_train.select_dtypes(exclude=[\"number\"]).columns.to_list()\n",
    "\n",
    "    cat_cols\n",
    "\n",
    "Out\\[28\\]:\n",
    "\n",
    "    ['month']\n",
    "\n",
    "In \\[29\\]:\n",
    "\n",
    "    for col in cat_cols:\n",
    "        X_train[col] = X_train[col].astype(\"category\")\n",
    "        X_test[col] = X_test[col].astype(\"category\")\n",
    "\n",
    "    <ipython-input-29-66ee9e31654a>:2: SettingWithCopyWarning: \n",
    "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
    "    Try using .loc[row_indexer,col_indexer] = value instead\n",
    "\n",
    "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "      X_train[col] = X_train[col].astype(\"category\")\n",
    "    <ipython-input-29-66ee9e31654a>:3: SettingWithCopyWarning: \n",
    "    A value is trying to be set on a copy of a slice from a DataFrame.\n",
    "    Try using .loc[row_indexer,col_indexer] = value instead\n",
    "\n",
    "    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "      X_test[col] = X_test[col].astype(\"category\")\n",
    "\n",
    "In \\[30\\]:\n",
    "\n",
    "    y_test.value_counts()\n",
    "\n",
    "Out\\[30\\]:\n",
    "\n",
    "    0    24878\n",
    "    1       21\n",
    "    Name: failure, dtype: int64\n",
    "\n",
    "In \\[31\\]:\n",
    "\n",
    "    print(f'Train datanshape: {X_train.shape}\\nTest data shape : {X_test.shape}')\n",
    "\n",
    "    Train datanshape: (99594, 9)\n",
    "    Test data shape : (24899, 9)\n",
    "\n",
    "Feature Engineering\n",
    "\n",
    "In \\[32\\]:\n",
    "\n",
    "    #numerical colums pipeline\n",
    "    num_pipeline = Pipeline(\n",
    "        [\n",
    "                  (\"std_scaler\", StandardScaler()),\n",
    "        ]\n",
    "    )\n",
    "    # categorical columns pipeline\n",
    "    cat_pipeline = Pipeline(\n",
    "        [\n",
    "            (\"one_hot_encoder\", OneHotEncoder(sparse=False, handle_unknown=\"ignore\")),\n",
    "        ]\n",
    "    )\n",
    "    # full pipeline\n",
    "    full_pipeline = ColumnTransformer(\n",
    "        [(\"num\", num_pipeline, num_cols), (\"cat\", cat_pipeline, cat_cols),]\n",
    "    )\n",
    "\n",
    "In \\[33\\]:\n",
    "\n",
    "    X_train_LR = full_pipeline.fit_transform(X_train)\n",
    "    X_test_LR = full_pipeline.transform(X_test)\n",
    "\n",
    "Model Building:\n",
    "\n",
    "1.  Modelling Pipeline for data preparation(Combination of oversampling\n",
    "    and undersampling the data ), modelling operation\n",
    "2.  CrossFold Validation\n",
    "3.  Set Parameters for Grid Search\n",
    "4.  Grid Search through predefined hyperparameters and fit model on your\n",
    "    training set by selecting the best hyperparameters.\n",
    "\n",
    "In \\[34\\]:\n",
    "\n",
    "    # example of evaluating a decision tree with random oversampling\n",
    "    from numpy import mean\n",
    "    from sklearn.datasets import make_classification\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from imblearn.pipeline import Pipeline\n",
    "    from imblearn.over_sampling import RandomOverSampler\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Logistic Regression Classifier<a href=\"#Logistic-Regression-Classifier\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[58\\]:\n",
    "\n",
    "    pipeline_lg = imbpipeline(steps=[['smote',SMOTE(random_state=11,\n",
    "                                                 sampling_strategy=0.1)],\n",
    "                                 ['under', RandomUnderSampler(sampling_strategy=0.5)], \n",
    "                                           ['classifier',LogisticRegression(C=1)]])\n",
    "    stratified_kfold_lg = StratifiedKFold(n_splits=10,\n",
    "                                      shuffle=True,\n",
    "                                      random_state=11)\n",
    "    # parameter for gridsearchcv\n",
    "    param_grid_lg = {'classifier__C':[0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "    # Gridsearch on parameter grid, use accuracy to determine the best model\n",
    "    #finding best hyperparameter using gridsearchcv\n",
    "    grid_search_lg = GridSearchCV(estimator=pipeline_lg,\n",
    "                               param_grid = param_grid_lg,\n",
    "                               scoring='accuracy',\n",
    "                               cv=stratified_kfold_lg,\n",
    "                               n_jobs=-1,\n",
    "                              error_score=\"raise\")\n",
    "\n",
    "In \\[59\\]:\n",
    "\n",
    "    cv = stratified_kfold_lg\n",
    "\n",
    "    # evaluate model\n",
    "\n",
    "    scores_lg = cross_val_score(pipeline_lg, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "\n",
    "    # summarize performance\n",
    "\n",
    "    print('Mean ROC AUC: %.3f' % mean(scores_lg))\n",
    "\n",
    "    Mean ROC AUC: 0.567\n",
    "\n",
    "In \\[37\\]:\n",
    "\n",
    "    # Fit model on the training data\n",
    "    grid_search_lg.fit(X_train_LR, y_train)\n",
    "    #taking the best cv score \n",
    "    cv_score_lg = grid_search_lg.best_score_\n",
    "    train_score_lg = grid_search_lg.score(X_train_LR, y_train)\n",
    "    #Evaluating the model accuracy using test_data\n",
    "    test_score_lg = grid_search_lg.score(X_test_LR, y_test)\n",
    "    y_pred_lg = grid_search_lg.predict(X_test_LR)\n",
    "    print(f'Test score: {test_score_lg}\\nTrain score: {train_score_lg}')\n",
    "    print(f'\\nConfusion matrix: \\n{confusion_matrix(y_test, y_pred_lg)}')\n",
    "    print(f'\\n Classification report: \\n{classification_report(y_test,y_pred_lg)}')\n",
    "\n",
    "    Test score: 0.9905217076991044\n",
    "    Train score: 0.9909733518083419\n",
    "\n",
    "    Confusion matrix: \n",
    "    [[24654   224]\n",
    "     [   12     9]]\n",
    "\n",
    "     Classification report: \n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "               0       1.00      0.99      1.00     24878\n",
    "               1       0.04      0.43      0.07        21\n",
    "\n",
    "        accuracy                           0.99     24899\n",
    "       macro avg       0.52      0.71      0.53     24899\n",
    "    weighted avg       1.00      0.99      0.99     24899\n",
    "\n",
    "Random OverSampling\n",
    "\n",
    "In \\[61\\]:\n",
    "\n",
    "    pipeline_lg = imbpipeline(steps=[['over',RandomOverSampler(sampling_strategy=0.1)],\n",
    "                                                 \n",
    "                                 ['under', RandomUnderSampler(sampling_strategy=0.5)], \n",
    "                                           ['classifier',LogisticRegression(C=1)]])\n",
    "    stratified_kfold_lg = StratifiedKFold(n_splits=10,\n",
    "                                      shuffle=True,\n",
    "                                      random_state=11)\n",
    "    # parameter for gridsearchcv\n",
    "    param_grid_lg = {'classifier__C':[0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "    # Gridsearch on parameter grid, use accuracy to determine the best model\n",
    "    #finding best hyperparameter using gridsearchcv\n",
    "    grid_search_lg = GridSearchCV(estimator=pipeline_lg,\n",
    "                               param_grid = param_grid_lg,\n",
    "                               scoring='accuracy',\n",
    "                               cv=stratified_kfold_lg,\n",
    "                               n_jobs=-1,\n",
    "                              error_score=\"raise\")\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "     \n",
    "\n",
    "In \\[62\\]:\n",
    "\n",
    "    # Fit model on the training data\n",
    "    grid_search_lg.fit(X_train_LR, y_train)\n",
    "    #taking the best cv score \n",
    "    cv_score_lg = grid_search_lg.best_score_\n",
    "    train_score_lg = grid_search_lg.score(X_train_LR, y_train)\n",
    "    #Evaluating the model accuracy using test_data\n",
    "    test_score_lg = grid_search_lg.score(X_test_LR, y_test)\n",
    "    y_pred_lg = grid_search_lg.predict(X_test_LR)\n",
    "    print(f'Test score: {test_score_lg}\\nTrain score: {train_score_lg}')\n",
    "    print(f'\\nConfusion matrix: \\n{confusion_matrix(y_test, y_pred_lg)}')\n",
    "    print(f'\\n Classification report: \\n{classification_report(y_test,y_pred_lg)}')\n",
    "\n",
    "    Test score: 0.9904413831880798\n",
    "    Train score: 0.990923147980802\n",
    "\n",
    "    Confusion matrix: \n",
    "    [[24652   226]\n",
    "     [   12     9]]\n",
    "\n",
    "     Classification report: \n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "               0       1.00      0.99      1.00     24878\n",
    "               1       0.04      0.43      0.07        21\n",
    "\n",
    "        accuracy                           0.99     24899\n",
    "       macro avg       0.52      0.71      0.53     24899\n",
    "    weighted avg       1.00      0.99      0.99     24899\n",
    "\n",
    "SMOTETOMEK\n",
    "\n",
    "In \\[66\\]:\n",
    "\n",
    "    from imblearn.combine import SMOTETomek\n",
    "    pipeline_lg = imbpipeline(steps=[['smote',SMOTETomek(random_state=11,\n",
    "                                                 sampling_strategy=0.1)],\n",
    "                                 ['under', RandomUnderSampler(sampling_strategy=0.5)], \n",
    "                                           ['classifier',LogisticRegression(C=1)]])\n",
    "    stratified_kfold_lg = StratifiedKFold(n_splits=10,\n",
    "                                      shuffle=True,\n",
    "                                      random_state=11)\n",
    "    # parameter for gridsearchcv\n",
    "    param_grid_lg = {'classifier__C':[0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "    # Gridsearch on parameter grid, use accuracy to determine the best model\n",
    "    #finding best hyperparameter using gridsearchcv\n",
    "    grid_search_lg = GridSearchCV(estimator=pipeline_lg,\n",
    "                               param_grid = param_grid_lg,\n",
    "                               scoring='accuracy',\n",
    "                               cv=stratified_kfold_lg,\n",
    "                               n_jobs=-1,\n",
    "                              error_score=\"raise\")\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    # Fit model on the training data\n",
    "    grid_search_lg.fit(X_train_LR, y_train)\n",
    "    #taking the best cv score \n",
    "    cv_score_lg = grid_search_lg.best_score_\n",
    "    train_score_lg = grid_search_lg.score(X_train_LR, y_train)\n",
    "    #Evaluating the model accuracy using test_data\n",
    "    test_score_lg = grid_search_lg.score(X_test_LR, y_test)\n",
    "    y_pred_lg = grid_search_lg.predict(X_test_LR)\n",
    "    print(f'Test score: {test_score_lg}\\nTrain score: {train_score_lg}')\n",
    "    print(f'\\nConfusion matrix: \\n{confusion_matrix(y_test, y_pred_lg)}')\n",
    "    print(f'\\n Classification report: \\n{classification_report(y_test,y_pred_lg)}')\n",
    "\n",
    "# Random Forest Classifier<a href=\"#Random-Forest-Classifier\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[38\\]:\n",
    "\n",
    "    pipeline_rfc = imbpipeline(steps=[['smote',SMOTE(random_state=11,\n",
    "                                                 sampling_strategy=0.1)],\n",
    "                                 ['under', RandomUnderSampler(sampling_strategy=0.5)], \n",
    "                                  ['classifier', RandomForestClassifier(random_state=11, n_estimators=200)]])\n",
    "    stratified_kfold_rfc = StratifiedKFold(n_splits=10,\n",
    "                                      shuffle=True,\n",
    "                                      random_state=11)\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 100, stop = 500, num = 100)]\n",
    "    # Hyperparameter tuning grid\n",
    "    random_grid = {'classifier__n_estimators': n_estimators\n",
    "                  }\n",
    "    # Gridsearch on parameter grid, use accuracy to determine the best model\n",
    "    grid_search_rfc = GridSearchCV(estimator=pipeline_rfc,\n",
    "                       \n",
    "                               param_grid =random_grid,\n",
    "                               scoring='accuracy',\n",
    "                               cv=stratified_kfold_rfc,\n",
    "                               n_jobs=-1,\n",
    "                              error_score=\"raise\")\n",
    "\n",
    "In \\[39\\]:\n",
    "\n",
    "    cv = stratified_kfold_rfc\n",
    "\n",
    "    # evaluate model\n",
    "\n",
    "    scores_rfc = cross_val_score(pipeline_rfc, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "\n",
    "    # summarize performance\n",
    "\n",
    "    print('Mean ROC AUC: %.3f' % mean(scores_rfc))\n",
    "\n",
    "    Mean ROC AUC: 0.872\n",
    "\n",
    "In \\[40\\]:\n",
    "\n",
    "    # Fit model on the training data\n",
    "    grid_search_rfc.fit(X_train_LR, y_train)\n",
    "    #taking the best cv score \n",
    "    cv_score_rfc = grid_search_rfc.best_score_\n",
    "    train_score_rfc = grid_search_rfc.score(X_train_LR, y_train)\n",
    "    #Evaluating the model accuracy using test_data\n",
    "    test_score_rfc = grid_search_rfc.score(X_test_LR, y_test)\n",
    "    y_pred_rfc = grid_search_rfc.predict(X_test_LR)\n",
    "    print(f'Test score: {test_score_rfc}\\nTrain score: {train_score_rfc}')\n",
    "    print(f'\\nConfusion matrix: \\n{confusion_matrix(y_test, y_pred_rfc)}')\n",
    "    print(f'\\n Classification report: \\n{classification_report(y_test,y_pred_rfc)}')\n",
    "\n",
    "    Test score: 0.9975501024137515\n",
    "    Train score: 0.9987348635459967\n",
    "\n",
    "    Confusion matrix: \n",
    "    [[24837    41]\n",
    "     [   20     1]]\n",
    "\n",
    "     Classification report: \n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "               0       1.00      1.00      1.00     24878\n",
    "               1       0.02      0.05      0.03        21\n",
    "\n",
    "        accuracy                           1.00     24899\n",
    "       macro avg       0.51      0.52      0.52     24899\n",
    "    weighted avg       1.00      1.00      1.00     24899\n",
    "\n",
    "# XGBoost Classifier<a href=\"#XGBoost-Classifier\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[41\\]:\n",
    "\n",
    "    from xgboost import XGBClassifier\n",
    "    #Building the pipeline with preprocessing steps and model definition\n",
    "    pipeline_xgb = imbpipeline(steps = [['smote',SMOTE(random_state=11,\n",
    "                                                 sampling_strategy=0.1)],\n",
    "                                 ['under', RandomUnderSampler(sampling_strategy=0.5)], \n",
    "                                    ['classifier', XGBClassifier(n_jobs=-1,grow_policy='lossguide',tree_method ='hist',n_estimators=100)]])\n",
    "\n",
    "    #Using the stratified_kfold method for K- Fold cross validation to avaoid over-fitting\n",
    "    stratified_kfold_xgb = StratifiedKFold(n_splits=10,\n",
    "                                           shuffle=True,\n",
    "                                           random_state=11)\n",
    "    # Hyperparameter tuning grid\n",
    "    XGB_param_grid = {'classifier__min_child_weight': [1, 5, 10],'classifier__gamma': [0.5, 1, 1.5, 2, 5],'classifier__subsample': [0.6, 0.8, 1.0],'classifier__max_depth': [3, 4, 5]}\n",
    "\n",
    "    # A parameter grid for XGBoostparams = {'min_child_weight': [1, 5, 10],'gamma': [0.5, 1, 1.5, 2, 5],'subsample': [0.6, 0.8, 1.0],'colsample_bytree': [0.6, 0.8, 1.0],'max_depth': [3, 4, 5]}\n",
    "    # Gridsearch on parameter grid, use accuracy to determine the best model\n",
    "    XGB_grid_search = GridSearchCV(estimator=pipeline_xgb,\n",
    "                               param_grid = XGB_param_grid,\n",
    "                               scoring='accuracy',\n",
    "                               cv=stratified_kfold_xgb,\n",
    "                               n_jobs=-1,\n",
    "                              error_score=\"raise\")\n",
    "\n",
    "In \\[42\\]:\n",
    "\n",
    "    cv = stratified_kfold_xgb\n",
    "\n",
    "    # evaluate model\n",
    "\n",
    "    scores_xgb = cross_val_score(pipeline_xgb, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "\n",
    "    # summarize performance\n",
    "\n",
    "    print('Mean ROC AUC: %.3f' % mean(scores_xgb))\n",
    "\n",
    "    Mean ROC AUC: 0.867\n",
    "\n",
    "In \\[43\\]:\n",
    "\n",
    "    # Fit model on the training data\n",
    "    XGB_grid_search.fit(X_train_LR, y_train)\n",
    "    #taking the best cv score \n",
    "    cv_score = XGB_grid_search.best_score_\n",
    "    train_score_xgb = XGB_grid_search.score(X_train_LR, y_train)\n",
    "    #Evaluating the model accuracy using test_data\n",
    "    test_score_xgb = XGB_grid_search.score(X_test_LR, y_test)\n",
    "    y_pred_XGBC = XGB_grid_search.predict(X_test_LR)\n",
    "    print(f'Test score: {test_score_xgb}\\nTrain score: {train_score_xgb}')\n",
    "    print(f'\\n Confusion matrix: \\n{confusion_matrix(y_test, y_pred_XGBC)}')\n",
    "    print(f'\\n Classification report: \\n{classification_report(y_test,y_pred_XGBC)}')\n",
    "\n",
    "    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
    "      warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
    "\n",
    "    [21:59:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
    "    Test score: 0.9969476685810675\n",
    "    Train score: 0.997580175512581\n",
    "\n",
    "     Confusion matrix: \n",
    "    [[24819    59]\n",
    "     [   17     4]]\n",
    "\n",
    "     Classification report: \n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "               0       1.00      1.00      1.00     24878\n",
    "               1       0.06      0.19      0.10        21\n",
    "\n",
    "        accuracy                           1.00     24899\n",
    "       macro avg       0.53      0.59      0.55     24899\n",
    "    weighted avg       1.00      1.00      1.00     24899\n",
    "\n",
    "Smotetomek\n",
    "\n",
    "# LGB Classifier<a href=\"#LGB-Classifier\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[53\\]:\n",
    "\n",
    "    import lightgbm as lgb\n",
    "\n",
    "    #Building the pipeline with preprocessing steps and model definition\n",
    "    pipeline_lgb = imbpipeline(steps = [['smote',SMOTE(random_state=11,\n",
    "                                                 sampling_strategy=0.1)],\n",
    "                                 ['under', RandomUnderSampler(sampling_strategy=0.5)], \n",
    "                                    ['classifier', lgb.LGBMClassifier(boosting_type='gbdt',  \n",
    "                            objective='binary', num_boost_round=2000, learning_rate=0.01, metric='auc')]])\n",
    "    #Using the stratified_kfold method for K- Fold cross validation to avaoid over-fitting\n",
    "    stratified_kfold_lgb = StratifiedKFold(n_splits=10,\n",
    "                                           shuffle=True,\n",
    "                                           random_state=11)\n",
    "    # Hyperparameter tuning grid\n",
    "    param_grid_lgb = {\n",
    "        'classifier__num_leaves': [31, 127],\n",
    "        'classifier__reg_alpha': [0.1, 0.5],\n",
    "        'classifier__min_data_in_leaf': [30, 50, 100, 300, 400],\n",
    "        'classifier__lambda_l1': [0, 1, 1.5],\n",
    "        'classifier__lambda_l2': [0, 1]\n",
    "        }\n",
    "\n",
    "    #  'lambda_l1': [0, 1, 1.5], A parameter grid for XGBoostparams = {'min_child_weight': [1, 5, 10],'gamma': [0.5, 1, 1.5, 2, 5],'subsample': [0.6, 0.8, 1.0],'colsample_bytree': [0.6, 0.8, 1.0],'max_depth': [3, 4, 5]}\n",
    "    # Gridsearch on parameter grid, use accuracy to determine the best model\n",
    "    LGB_grid_search = GridSearchCV(estimator=pipeline_lgb,\n",
    "                               param_grid = param_grid_lgb,\n",
    "                               scoring='accuracy',\n",
    "                               cv=stratified_kfold_lgb,\n",
    "                               n_jobs=-1,\n",
    "                              error_score=\"raise\")\n",
    "\n",
    "In \\[54\\]:\n",
    "\n",
    "    cv = stratified_kfold_lgb\n",
    "\n",
    "    # evaluate model\n",
    "\n",
    "    scores_lgb = cross_val_score(pipeline_lgb, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "\n",
    "    # summarize performance\n",
    "\n",
    "    print('Mean ROC AUC: %.3f' % mean(scores_lgb))\n",
    "\n",
    "    Mean ROC AUC: 0.858\n",
    "\n",
    "In \\[55\\]:\n",
    "\n",
    "    # Fit model on the training data\n",
    "    LGB_grid_search.fit(X_train_LR, y_train)\n",
    "    #taking the best cv score \n",
    "    cv_score =LGB_grid_search.best_score_\n",
    "    train_score = LGB_grid_search.score(X_train_LR, y_train)\n",
    "    #Evaluating the model accuracy using test_data\n",
    "    test_score = LGB_grid_search.score(X_test_LR, y_test)\n",
    "    y_pred_LGBC = LGB_grid_search.predict(X_test_LR)\n",
    "    print(f'Test score: {test_score}\\nTrain score: {train_score}')\n",
    "    print(f'\\n Confusion matrix: \\n{confusion_matrix(y_test, y_pred_LGBC)}')\n",
    "    print(f'\\n Classification report: \\n{classification_report(y_test,y_pred_LGBC)}')\n",
    "\n",
    "    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
    "      _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
    "\n",
    "    [LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
    "    [LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n",
    "    [LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
    "    [LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n",
    "    Test score: 0.9980320494798988\n",
    "    Train score: 0.99891559732514\n",
    "\n",
    "     Confusion matrix: \n",
    "    [[24847    31]\n",
    "     [   18     3]]\n",
    "\n",
    "     Classification report: \n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "               0       1.00      1.00      1.00     24878\n",
    "               1       0.09      0.14      0.11        21\n",
    "\n",
    "        accuracy                           1.00     24899\n",
    "       macro avg       0.54      0.57      0.55     24899\n",
    "    weighted avg       1.00      1.00      1.00     24899\n",
    "\n",
    "# Decision Tree Classifier<a href=\"#Decision-Tree-Classifier\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[47\\]:\n",
    "\n",
    "    pipeline_dt = imbpipeline(steps=[['smote',SMOTE(random_state=11,\n",
    "                                                 sampling_strategy=0.1)],\n",
    "                                 ['under', RandomUnderSampler(sampling_strategy=0.5)], \n",
    "                                  ['classifier', RandomForestClassifier(random_state=100, n_estimators=200)]])\n",
    "    stratified_kfold_dt = StratifiedKFold(n_splits=10,\n",
    "                                      shuffle=True,\n",
    "                                      random_state=11)\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 10, stop = 50, num = 100)]\n",
    "    # Hyperparameter tuning grid\n",
    "    random_grid = {'classifier__n_estimators': n_estimators\n",
    "                  }\n",
    "    # Gridsearch on parameter grid, use accuracy to determine the best model\n",
    "    grid_search_dt = GridSearchCV(estimator=pipeline_rfc,\n",
    "                       \n",
    "                               param_grid =random_grid,\n",
    "                               scoring='accuracy',\n",
    "                               cv=stratified_kfold_rfc,\n",
    "                               n_jobs=-1,\n",
    "                              error_score=\"raise\")\n",
    "\n",
    "In \\[48\\]:\n",
    "\n",
    "    cv = stratified_kfold_dt\n",
    "\n",
    "    # evaluate model\n",
    "\n",
    "    scores_dt = cross_val_score(pipeline_dt, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "\n",
    "    # summarize performance\n",
    "\n",
    "    print('Mean ROC AUC: %.3f' % mean(scores_dt))\n",
    "\n",
    "    Mean ROC AUC: 0.864\n",
    "\n",
    "In \\[49\\]:\n",
    "\n",
    "    # Fit model on the training data\n",
    "    grid_search_dt.fit(X_train_LR, y_train)\n",
    "    #taking the best cv score \n",
    "    cv_score_dt = grid_search_dt.best_score_\n",
    "    train_score_dt = grid_search_dt.score(X_train_LR, y_train)\n",
    "    #Evaluating the model accuracy using test_data\n",
    "    test_score_dt = grid_search_dt.score(X_test_LR, y_test)\n",
    "    y_pred_dt = grid_search_dt.predict(X_test_LR)\n",
    "    print(f'Test score: {test_score_dt}\\nTrain score: {train_score_dt}')\n",
    "    print(f'\\nConfusion matrix: \\n{confusion_matrix(y_test, y_pred_dt)}')\n",
    "    print(f'\\n Classification report: \\n{classification_report(y_test,y_pred_dt)}')\n",
    "\n",
    "    Test score: 0.9978312382023374\n",
    "    Train score: 0.9986244151254091\n",
    "\n",
    "    Confusion matrix: \n",
    "    [[24844    34]\n",
    "     [   20     1]]\n",
    "\n",
    "     Classification report: \n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "               0       1.00      1.00      1.00     24878\n",
    "               1       0.03      0.05      0.04        21\n",
    "\n",
    "        accuracy                           1.00     24899\n",
    "       macro avg       0.51      0.52      0.52     24899\n",
    "    weighted avg       1.00      1.00      1.00     24899\n",
    "\n",
    "In \\[63\\]:\n",
    "\n",
    "    pipeline_dt = imbpipeline(steps=[['over',RandomOverSampler(random_state=11,\n",
    "                                                 sampling_strategy=0.1)],\n",
    "                                 ['under', RandomUnderSampler(sampling_strategy=0.5)], \n",
    "                                  ['classifier', RandomForestClassifier(random_state=100, n_estimators=200)]])\n",
    "    stratified_kfold_dt = StratifiedKFold(n_splits=10,\n",
    "                                      shuffle=True,\n",
    "                                      random_state=11)\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 10, stop = 50, num = 100)]\n",
    "    # Hyperparameter tuning grid\n",
    "    random_grid = {'classifier__n_estimators': n_estimators\n",
    "                  }\n",
    "    # Gridsearch on parameter grid, use accuracy to determine the best model\n",
    "    grid_search_dt = GridSearchCV(estimator=pipeline_rfc,\n",
    "                       \n",
    "                               param_grid =random_grid,\n",
    "                               scoring='accuracy',\n",
    "                               cv=stratified_kfold_rfc,\n",
    "                               n_jobs=-1,\n",
    "                              error_score=\"raise\")\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    # Fit model on the training data\n",
    "    grid_search_dt.fit(X_train_LR, y_train)\n",
    "    #taking the best cv score \n",
    "    cv_score_dt = grid_search_dt.best_score_\n",
    "    train_score_dt = grid_search_dt.score(X_train_LR, y_train)\n",
    "    #Evaluating the model accuracy using test_data\n",
    "    test_score_dt = grid_search_dt.score(X_test_LR, y_test)\n",
    "    y_pred_dt = grid_search_dt.predict(X_test_LR)\n",
    "    print(f'Test score: {test_score_dt}\\nTrain score: {train_score_dt}')\n",
    "    print(f'\\nConfusion matrix: \\n{confusion_matrix(y_test, y_pred_dt)}')\n",
    "    print(f'\\n Classification report: \\n{classification_report(y_test,y_pred_dt)}')\n",
    "\n",
    "In \\[ \\]:"
   ],
   "attachments": {
    "vertopal_ff7a4e3872b24f67b72ab8786db2a741/0b0f79b6909e4cd01d260d98dbd2468a8b451f52.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD5CAYAAAA9SqL2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\n"
    },
    "vertopal_ff7a4e3872b24f67b72ab8786db2a741/9c29c00a83aa59b201724f6aac2ec1ef68ebac99.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD7CAYAAABqvuNzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\nkhoDQZIEGAiSpOb/AMmLRRkjj85OAAAAAElFTkSuQmCC\n"
    },
    "vertopal_ff7a4e3872b24f67b72ab8786db2a741/67213e103aac42415d73b8fa5585cc21980d37e7.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEXCAYAAACQ3VJYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\nktSL/w/NZSxrJfdF/gAAAABJRU5ErkJggg==\n"
    },
    "vertopal_ff7a4e3872b24f67b72ab8786db2a741/f2b0f5d92544571f294dccf4d9b0140c950f9862.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEZCAYAAACZwO5kAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\ncbngq7AZCQAAAABJRU5ErkJggg==\n"
    }
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
